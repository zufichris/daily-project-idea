# Mini-Game AI: Rock-Paper-Scissors with Learned Strategy

## Overview

This project aims to develop a simple Rock-Paper-Scissors (RPS) AI agent that learns optimal strategies through reinforcement learning.  The focus will be on a quick implementation using a lightweight reinforcement learning algorithm, allowing for prototyping and evaluation within a short timeframe. The significance lies in demonstrating a fundamental AI concept (reinforcement learning) in a highly accessible and understandable game context.

## Technologies & Tools

- Python 3
- Libraries: `numpy`, `random` (possibly `gym` for a more structured RL environment, but not strictly necessary for a minimal implementation)

## Features & Requirements

- **Core Features:**
    - Agent plays RPS against a random opponent.
    - Agent maintains a simple strategy based on past wins/losses (e.g., using win rates for each choice).
    - Agent updates its strategy after each round based on the outcome.
    - Agentâ€™s performance (win rate) is tracked and displayed.
- **Optional Features:**
    - Visualization of the agent's strategy evolution over time (simple plot).
    - Ability to play against a human opponent.


## Implementation Steps

1. **Basic RPS Game Logic:** Implement the core RPS game mechanics, including determining the winner of each round.
2. **Agent Strategy:**  Create a simple strategy for the AI agent, initially random, that tracks the win rate of each choice (rock, paper, scissors).
3. **Reinforcement Learning Loop:** Implement a loop where the agent plays multiple rounds, updates its strategy based on wins/losses using a simple approach (e.g., slightly increasing the probability of the winning choice).
4. **Performance Tracking:** Record and display the agent's win rate over time.
5. **Optional Visualization:**  If time permits, add a plot showing the evolution of the agent's strategy.


## Challenges & Considerations

- **Strategy Convergence:**  The agent's strategy might not converge to a perfect solution quickly, due to the simplicity of the learning algorithm. Experimenting with different update rules might be necessary.
- **Overfitting:** The agent's learning might overfit to the random opponent's behavior.  A slightly more sophisticated opponent (e.g., one that slightly adapts) could be implemented for a more robust test.


## Learning Outcomes

- Practical application of basic reinforcement learning principles.
- Experience with iterative development and performance evaluation in an AI context.

