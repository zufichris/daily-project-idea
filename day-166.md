# Micro-Gesture Recognition for Smart Home Control

## Overview

This project aims to develop a prototype for a smart home control system using micro-gestures captured via a webcam.  The system will recognize simple hand gestures performed in front of the camera and trigger corresponding actions within a simulated smart home environment. This offers a hands-free and intuitive alternative to traditional voice or touch-based controls.

## Technologies & Tools

- **Programming Language:** Python
- **Libraries:** OpenCV (computer vision), MediaPipe (hand tracking),  simple-websocket-server (optional for network communication)
- **Tools:**  Webcam, Python IDE (e.g., VS Code, PyCharm)

## Features & Requirements

- **Gesture Recognition:**  Recognize at least three distinct micro-gestures (e.g., hand wave for lights on/off, fist for volume up, open palm for volume down).
- **Action Triggering:**  Simulate smart home actions based on recognized gestures (e.g., printing to console,  changing simulated light/temperature values).
- **Real-time Processing:**  Process webcam feed in real-time with minimal latency.
- **Gesture Visualization:**  Overlay recognized gestures on the webcam feed for visual feedback.
- **Model Persistence (Optional):**  Save and load a trained gesture recognition model for future use.

## Implementation Steps

1. **Setup Environment:** Install necessary libraries (OpenCV, MediaPipe) and set up a Python project.
2. **Hand Tracking:** Integrate MediaPipe's hand tracking solution to detect and track hand landmarks from the webcam feed.
3. **Gesture Classification:** Implement a simple gesture classification algorithm based on landmark positions (e.g., using distance thresholds or simple machine learning techniques).
4. **Action Mapping:** Map classified gestures to specific smart home actions (e.g., using a dictionary).
5. **Display and Feedback:** Display the webcam feed with gesture overlays and print the triggered action to the console.


## Challenges & Considerations

- **Robustness:**  Dealing with variations in lighting, hand size, and background clutter can affect gesture recognition accuracy.  Experiment with different pre-processing techniques (e.g., background subtraction).
- **Real-time Performance:**  Balancing processing speed and accuracy is crucial for real-time performance.  Optimize code for efficiency and consider using faster algorithms if necessary.


## Learning Outcomes

- **Computer Vision Fundamentals:** This project reinforces understanding of real-time image processing, object detection (hand tracking), and feature extraction.
- **Machine Learning Basics:** Implementing a simple gesture classification algorithm, even without complex model training, introduces core ML concepts like feature engineering and classification.

